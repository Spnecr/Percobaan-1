{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['summary','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anggota Komisi VII DPR RI Rofik Hananto menyay...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Presiden Joko Widodo telah memerintahkan Wakil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wakil Ketua MPR RI Dr. H. M. Hidayat Nur Wahid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim Kedokteran dan Kesehatan (Dokkes) Polri te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ketua MPR RI Bambang Soesatyo telah diangkat s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  label\n",
       "0  Anggota Komisi VII DPR RI Rofik Hananto menyay...      1\n",
       "1  Presiden Joko Widodo telah memerintahkan Wakil...      0\n",
       "2  Wakil Ketua MPR RI Dr. H. M. Hidayat Nur Wahid...      0\n",
       "3  Tim Kedokteran dan Kesehatan (Dokkes) Polri te...      0\n",
       "4  Ketua MPR RI Bambang Soesatyo telah diangkat s...      0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=8000, replace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summary    5\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fikri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_summary(summary):\n",
    "    # Convert text to lowercase\n",
    "    summary = summary.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    summary = re.sub(r'[^a-zA-Z\\s]', '', summary)\n",
    "    \n",
    "    # Remove links\n",
    "    summary = re.sub(r'http\\S+', '', summary)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(summary)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Initialize Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Perform stemming\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    \n",
    "    # Join the stemmed words back into a single string\n",
    "    cleaned_summary = ' '.join(stemmed_words)\n",
    "    \n",
    "    return cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_summary'] = df['summary'].apply(lambda x: clean_summary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4147\n",
       "1    3848\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_summary'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[614 217]\n",
      " [309 459]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70       831\n",
      "           1       0.68      0.60      0.64       768\n",
      "\n",
      "    accuracy                           0.67      1599\n",
      "   macro avg       0.67      0.67      0.67      1599\n",
      "weighted avg       0.67      0.67      0.67      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Confusion Matrix:\n",
      "[[570 261]\n",
      " [350 418]]\n",
      "\n",
      "Logistic Regression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       831\n",
      "           1       0.62      0.54      0.58       768\n",
      "\n",
      "    accuracy                           0.62      1599\n",
      "   macro avg       0.62      0.62      0.61      1599\n",
      "weighted avg       0.62      0.62      0.62      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "lr_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Confusion matrix and classification report for logistic regression\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "class_report_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression - Confusion Matrix:\")\n",
    "print(conf_matrix_lr)\n",
    "print(\"\\nLogistic Regression - Classification Report:\")\n",
    "print(class_report_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Confusion Matrix:\n",
      "[[549 282]\n",
      " [327 441]]\n",
      "\n",
      "SVM - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64       831\n",
      "           1       0.61      0.57      0.59       768\n",
      "\n",
      "    accuracy                           0.62      1599\n",
      "   macro avg       0.62      0.62      0.62      1599\n",
      "weighted avg       0.62      0.62      0.62      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Confusion matrix and classification report for SVM\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM - Confusion Matrix:\")\n",
    "print(conf_matrix_svm)\n",
    "print(\"\\nSVM - Classification Report:\")\n",
    "print(class_report_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: rill\n"
     ]
    }
   ],
   "source": [
    "def predict_fake_or_real(summary):\n",
    "    # Clean the input text\n",
    "    cleaned_summary = clean_summary(summary)\n",
    "    \n",
    "    # Transform the cleaned text using the TF-IDF vectorizer\n",
    "    text_tfidf = tfidf_vectorizer.transform([cleaned_summary])\n",
    "    \n",
    "    # Use the trained classifier to predict\n",
    "    prediction = svm_classifier.predict(text_tfidf)\n",
    "    \n",
    "    # Map prediction to label\n",
    "    if(prediction[0] == 1):\n",
    "        label = 'fake'\n",
    "    \n",
    "    elif(prediction[0] == 0):\n",
    "        label = 'rill'\n",
    "\n",
    "    \n",
    "    return label\n",
    "\n",
    "# Example usage:\n",
    "input_text = 'Tim Kedokteran dan Kesehatan (Dokkes) Polri telah menerima 14 kantong jenazah korban kebakaran Depo Plumpang, Jakarta Utara. Tim Dokkes Polri mengirimkan korban luka ke beberapa rumah sakit terdekat guna mendapatkan perawatan lebih lanjut. Tim Labfor dan Inafis'\n",
    "prediction = predict_fake_or_real(input_text)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: fake\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_text = 'Kim jong un jadi presiden Indonesia'\n",
    "prediction = predict_fake_or_real(input_text)\n",
    "print(\"Prediction:\", prediction)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
